{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7891231-3313-4d3b-82f9-3f906308b167",
   "metadata": {},
   "source": [
    "# CS 634 Midterm Project              By Chike Egbuchulam(coe5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481c600f-4cf5-4320-b546-8168d59dfce4",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496cc2ad-238d-4e24-be34-d90a1dcb2dce",
   "metadata": {},
   "source": [
    "First you want to import the libraries essential to run the the FP and Apriori Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23ca2a48-4096-430e-ba94-b18a03350e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlxtend.frequent_patterns import apriori,fpgrowth, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import time\n",
    "import itertools\n",
    "from bfassociationrules import assocRules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd032f4-d3c2-4ad0-8d65-b415b094b187",
   "metadata": {},
   "source": [
    "### Set  the initital variables as well as the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6831ec83-a020-4cfa-a447-50139ed71efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory: C:\\Users\\egbuc\\cs634\\Egbuchulam_Chike_midtermproject\n",
      "Tables directory: C:\\Users\\egbuc\\cs634\\Egbuchulam_Chike_midtermproject\\tables\n"
     ]
    }
   ],
   "source": [
    "dbfile = \"\"\n",
    "stores = [\"Alice's Bakery\", \"Bob's Breakfast\", \"Charlie's Cafe\", \"Desayuno de David\", \"Eddie's Eatery\"]\n",
    "supportValue, confidenceValue = 0, 0\n",
    "\n",
    "base_dir = os.getcwd()\n",
    "tables_dir = os.path.join(base_dir, \"tables\")\n",
    "\n",
    "print(\"Base directory:\", base_dir)\n",
    "print(\"Tables directory:\", tables_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c31febd-d9ea-4893-8aec-cb40234081b9",
   "metadata": {},
   "source": [
    "### Now let's get the Minimum Support and Minimimum Confidence values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a856231-0c8e-484f-9487-fc2d82375916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the minimum support % you want (0-100):  10\n",
      "Please enter the minimum confidence % you want (0-100):  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support 10.0 %\n",
      "Confidence 20.0 %\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    sV = input(\"Please enter the minimum support % you want (0-100): \")\n",
    "    try:\n",
    "        supportValue = float(sV) / 100\n",
    "    except ValueError:\n",
    "        print(\"Please input a numeric value\")\n",
    "        continue\n",
    "    if 0.0 <= supportValue <= 1.00:\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid selection\")\n",
    "\n",
    "while True:\n",
    "    cV = input(\"Please enter the minimum confidence % you want (0-100): \")\n",
    "    try:\n",
    "        confidenceValue = float(cV) / 100\n",
    "    except ValueError:\n",
    "        print(\"Please input a numeric value\")\n",
    "        continue\n",
    "    if 0.0 <= confidenceValue <= 1.0:\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid selection\")\n",
    "print(\"Support {} %\".format(supportValue * 100))\n",
    "print(\"Confidence {} %\".format(confidenceValue * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89498e52-3468-4331-840f-2f26df2d4101",
   "metadata": {},
   "source": [
    "### Now we'll run theses values for each database with our algorithm while also running the aprioiri and FP growth algorithms for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942f7674-80a4-459f-b265-ef1a23a752b7",
   "metadata": {},
   "source": [
    "## Alice's Bakery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f1830a-edaa-46a9-89e1-d91f8a7af9d1",
   "metadata": {},
   "source": [
    " Here is the transaction table for Alice's bakery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184dfd0d-4001-4ef0-931e-3b7d4c745345",
   "metadata": {},
   "source": [
    "### Here is the transaction table for Alice's bakery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a186fd3-bfcf-4d4d-9676-e8332df46ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Bread'}, {'Scandinavian'}, {'Jam', 'Hot chocolate', 'Cookies'}, {'Muffin'}, {'Bread', 'Coffee', 'Pastry'}, {'Medialuna', 'Pastry', 'Muffin'}, {'Medialuna', 'Pastry', 'Coffee', 'Tea'}, {'Bread', 'Pastry'}, {'Muffin', 'Bread'}, {'Medialuna', 'Scandinavian'}, {'Medialuna', 'Bread'}, {'Tea', 'Pastry', 'Jam', 'Coffee'}, {'Bread', 'Coffee'}, {'Medialuna', 'Bread', 'Pastry'}, {'Mineral water', 'Scandinavian'}, {'Medialuna', 'Bread', 'Coffee'}, {'Hot chocolate'}, {'Farm House'}, {'Bread', 'Farm House'}, {'Medialuna', 'Bread'}, {'Medialuna', 'Bread', 'Coffee'}, {'Jam'}, {'Muffin', 'Scandinavian'}, {'Bread'}, {'Scandinavian'}, {'Fudge'}, {'Scandinavian'}, {'Bread', 'Coffee'}, {'Bread', 'Jam'}, {'Bread'}, {'Muffin', 'Scandinavian'}, {'Coffee'}, {'Muffin', 'Coffee'}, {'Muffin', 'Scandinavian'}, {'Tea', 'Bread'}, {'Bread', 'Coffee'}, {'Tea', 'Bread'}, {'Scandinavian'}, {'Muffin', 'Juice', 'Coffee'}, {'Scandinavian'}]\n"
     ]
    }
   ],
   "source": [
    "dbfile = os.path.join(tables_dir, \"alicebakery001.csv\")\n",
    "transactions = pd.read_csv(dbfile, usecols=[\"ItemsPurchased\"])\n",
    "transactions_set = transactions[\"ItemsPurchased\"].apply(lambda x: set(item.strip() for item in x.split(\",\"))).tolist()\n",
    "unique_items = set().union(*transactions_set)\n",
    "print(transactions_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127417b7-39d5-4a81-bd61-8b85d52f755f",
   "metadata": {},
   "source": [
    "### Now lets run the algorithm with the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47ffe72d-0ff8-4ee5-b5f9-251f5e504fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bStart = time.perf_counter()\n",
    "[fSets,rules] = assocRules(unique_items,transactions_set,supportValue,confidenceValue)\n",
    "bEnd = time.perf_counter()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc702bb4-9050-4f0e-91c1-dae0e157212f",
   "metadata": {},
   "source": [
    "### Here are the frequent sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4445a72f-d919-4ab2-a8c1-d17673dd4d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Medialuna', 'Bread'}, {'Bread', 'Coffee'}]\n"
     ]
    }
   ],
   "source": [
    "print(fSets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedb62aa-f794-45d1-9808-1531806028d4",
   "metadata": {},
   "source": [
    "### Here are the rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8a14bca-41bf-4d0a-b73a-504627114c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule 1: Medialuna ===> Bread \t Confidence :1.0\n",
      "\n",
      "\n",
      "Rule 2: Bread ===> Medialuna \t Confidence :0.5\n",
      "\n",
      "\n",
      "Rule 3: Bread ===> Coffee \t Confidence :0.5\n",
      "\n",
      "\n",
      "Rule 4: Coffee ===> Bread \t Confidence :1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if(rules != [] and supportValue!=0):\n",
    "    i = 1\n",
    "    for (a, b, c) in rules:\n",
    "        print(f\"Rule {i}: {a} ===> {b} \\t Confidence :{c}\")\n",
    "        print(\"\\n\")\n",
    "        i += 1\n",
    "else:\n",
    "    if supportValue == 0:\n",
    "            print(\n",
    "                \"At 0% support I have to look at possible menu pairing as a rule even if it happens only once. \"\n",
    "                \"So in other words, you're trying to waste my time so here is the whole list of transactions.\"\n",
    "            )\n",
    "            # print(transactions)\n",
    "    \n",
    "    if supportValue != 0 and len(rules) == 0:\n",
    "        print(\"There are no rules that satisfy these minimum values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64962577-332f-4762-8f6a-d890d46f8f28",
   "metadata": {},
   "source": [
    "### Here's how it compares to other algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e4b5dc1-0d86-4e72-9bb7-58de498f05bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apriori check:\n",
      "    support            itemsets\n",
      "0    0.450             (Bread)\n",
      "1    0.275            (Coffee)\n",
      "2    0.100               (Jam)\n",
      "3    0.200         (Medialuna)\n",
      "4    0.200            (Muffin)\n",
      "5    0.150            (Pastry)\n",
      "6    0.250      (Scandinavian)\n",
      "7    0.100               (Tea)\n",
      "8    0.150     (Bread, Coffee)\n",
      "9    0.125  (Medialuna, Bread)\n",
      "Our Association Algorithm: 0.0033 seconds\n",
      "Apriori:0.0204 seconds\n",
      "FP-Growth: 0.0161 seconds\n"
     ]
    }
   ],
   "source": [
    "tList = transactions[\"ItemsPurchased\"].apply(lambda x: [item.strip() for item in x.split(\",\")]).tolist()\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(tList).transform(tList)\n",
    "df_encoded = pd.DataFrame(te_array, columns=te.columns_)\n",
    "\n",
    "aStart = time.perf_counter()\n",
    "frequent_items = apriori(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "aEnd = time.perf_counter()\n",
    "print(f\"Apriori check:\\n {frequent_items}\")\n",
    "fStart= time.perf_counter()\n",
    "frequent_items = fpgrowth(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "fEnd = time.perf_counter() \n",
    "\n",
    "print(f\"Our Association Algorithm: {bEnd - bStart:.4f} seconds\")\n",
    "print(f\"Apriori:{aEnd - aStart:.4f} seconds\")\n",
    "print(f\"FP-Growth:{fEnd - fStart: .4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a798a6e-29ce-4c62-8664-4882c82c4fd9",
   "metadata": {},
   "source": [
    "### Now for the rest of the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cab03d-fd1f-4e26-96ad-e369e94805f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98603478-5f10-4562-8c73-054cddd385e2",
   "metadata": {},
   "source": [
    "## Bob's Breakfast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad78ac4f-810a-46d7-822c-3a65f915534f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egbuc\\cs634\\Egbuchulam_Chike_midtermproject\\tables\\bobsbreakfast001.csv\n",
      "Frequent Sets: [{'Tea', 'Coffee'}]\n",
      "\n",
      "\n",
      "Rule 1: Coffee ===> Tea \t Confidence :1.0\n",
      "\n",
      "\n",
      "Rule 2: Tea ===> Coffee \t Confidence :1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dbfile = os.path.join(tables_dir, \"bobsbreakfast001.csv\")\n",
    "transactions = pd.read_csv(dbfile, usecols=[\"ItemsPurchased\"])\n",
    "transactions_set = transactions[\"ItemsPurchased\"].apply(lambda x: set(item.strip() for item in x.split(\",\"))).tolist()\n",
    "unique_items = set().union(*transactions_set)\n",
    "print(dbfile)\n",
    "\n",
    "bStart = time.perf_counter()\n",
    "[fSets,rules] = assocRules(unique_items,transactions_set,supportValue,confidenceValue)\n",
    "bEnd = time.perf_counter()\n",
    "\n",
    "\n",
    "print(f\"Frequent Sets: {fSets}\")\n",
    "print('\\n')\n",
    "\n",
    "if(rules != [] and supportValue!=0):\n",
    "    i = 1\n",
    "    for (a, b, c) in rules:\n",
    "        print(f\"Rule {i}: {a} ===> {b} \\t Confidence :{c}\")\n",
    "        print(\"\\n\")\n",
    "        i += 1\n",
    "else:\n",
    "    if supportValue == 0:\n",
    "        print(\n",
    "            \"At 0% support I have to look at possible menu pairing as a rule even if it happens only once. \"\n",
    "            \"So in other words, you're trying to waste my time so here is the whole list of transactions.\"\n",
    "        )\n",
    "        # print(transactions)\n",
    "    \n",
    "    if supportValue != 0 and len(rules) == 0:\n",
    "        print(\"There are no rules that satisfy these minimum values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851afd9e-02e1-4b24-ab0a-e0e08d269c1c",
   "metadata": {},
   "source": [
    "#### Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51c941e3-f3bb-4115-b87b-972f9ba56d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apriori check:\n",
      "    support             itemsets\n",
      "0    0.275              (Bread)\n",
      "1    0.475             (Coffee)\n",
      "2    0.100              (Fudge)\n",
      "3    0.100  (Hearty & Seasonal)\n",
      "4    0.100             (Muffin)\n",
      "5    0.125       (Scandinavian)\n",
      "6    0.200                (Tea)\n",
      "7    0.100        (Tea, Coffee)\n",
      "Our Association Algorithm: 0.0037 seconds\n",
      "Apriori:0.0156 seconds\n",
      "FP-Growth: 0.0136 seconds\n"
     ]
    }
   ],
   "source": [
    "tList = transactions[\"ItemsPurchased\"].apply(lambda x: [item.strip() for item in x.split(\",\")]).tolist()\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(tList).transform(tList)\n",
    "df_encoded = pd.DataFrame(te_array, columns=te.columns_)\n",
    "\n",
    "aStart = time.perf_counter()\n",
    "frequent_items = apriori(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "aEnd = time.perf_counter()\n",
    "print(f\"Apriori check:\\n {frequent_items}\")\n",
    "fStart= time.perf_counter()\n",
    "frequent_items = fpgrowth(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "fEnd = time.perf_counter() \n",
    "\n",
    "print(f\"Our Association Algorithm: {bEnd - bStart:.4f} seconds\")\n",
    "print(f\"Apriori:{aEnd - aStart:.4f} seconds\")\n",
    "print(f\"FP-Growth:{fEnd - fStart: .4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2371d7ac-5670-47dd-977f-7ecb9e29de24",
   "metadata": {},
   "source": [
    "## Charlie's Cafe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2a08572-e139-40eb-8027-4bf7ec30b2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egbuc\\cs634\\Egbuchulam_Chike_midtermproject\\tables\\charliescafe001.csv\n",
      "Frequent Sets: [{'Coffee', 'Pastry'}, {'Bread', 'Coffee'}]\n",
      "\n",
      "\n",
      "Rule 1: Pastry ===> Coffee \t Confidence :1.0\n",
      "\n",
      "\n",
      "Rule 2: Bread ===> Coffee \t Confidence :1.0\n",
      "\n",
      "\n",
      "Rule 3: Coffee ===> Pastry \t Confidence :0.5\n",
      "\n",
      "\n",
      "Rule 4: Coffee ===> Bread \t Confidence :0.5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dbfile = os.path.join(tables_dir, \"charliescafe001.csv\")\n",
    "transactions = pd.read_csv(dbfile, usecols=[\"ItemsPurchased\"])\n",
    "transactions_set = transactions[\"ItemsPurchased\"].apply(lambda x: set(item.strip() for item in x.split(\",\"))).tolist()\n",
    "unique_items = set().union(*transactions_set)\n",
    "print(dbfile)\n",
    "\n",
    "bStart = time.perf_counter()\n",
    "[fSets,rules] = assocRules(unique_items,transactions_set,supportValue,confidenceValue)\n",
    "bEnd = time.perf_counter()\n",
    "\n",
    "\n",
    "print(f\"Frequent Sets: {fSets}\")\n",
    "print('\\n')\n",
    "\n",
    "if(rules != [] and supportValue!=0):\n",
    "    i = 1\n",
    "    for (a, b, c) in rules:\n",
    "        print(f\"Rule {i}: {a} ===> {b} \\t Confidence :{c}\")\n",
    "        print(\"\\n\")\n",
    "        i += 1\n",
    "else:\n",
    "    if supportValue == 0:\n",
    "        print(\n",
    "            \"At 0% support I have to look at possible menu pairing as a rule even if it happens only once. \"\n",
    "            \"So in other words, you're trying to waste my time so here is the whole list of transactions.\"\n",
    "        )\n",
    "        # print(transactions)\n",
    "\n",
    "    if supportValue != 0 and len(rules) == 0:\n",
    "        print(\"There are no rules that satisfy these minimum values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71ea3b0-88fb-4e74-a7de-708429c05c15",
   "metadata": {},
   "source": [
    "#### Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ae3f943-1b5b-4c1a-a926-aef89815e7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apriori check:\n",
      "    support          itemsets\n",
      "0    0.300           (Bread)\n",
      "1    0.525          (Coffee)\n",
      "2    0.150      (Farm House)\n",
      "3    0.100          (Muffin)\n",
      "4    0.250          (Pastry)\n",
      "5    0.125             (Tea)\n",
      "6    0.100   (Bread, Coffee)\n",
      "7    0.150  (Pastry, Coffee)\n",
      "Our Association Algorithm: 0.0023 seconds\n",
      "Apriori:0.0167 seconds\n",
      "FP-Growth: 0.0144 seconds\n"
     ]
    }
   ],
   "source": [
    "tList = transactions[\"ItemsPurchased\"].apply(lambda x: [item.strip() for item in x.split(\",\")]).tolist()\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(tList).transform(tList)\n",
    "df_encoded = pd.DataFrame(te_array, columns=te.columns_)\n",
    "\n",
    "aStart = time.perf_counter()\n",
    "frequent_items = apriori(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "aEnd = time.perf_counter()\n",
    "print(f\"Apriori check:\\n {frequent_items}\")\n",
    "fStart= time.perf_counter()\n",
    "frequent_items = fpgrowth(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "fEnd = time.perf_counter() \n",
    "\n",
    "print(f\"Our Association Algorithm: {bEnd - bStart:.4f} seconds\")\n",
    "print(f\"Apriori:{aEnd - aStart:.4f} seconds\")\n",
    "print(f\"FP-Growth:{fEnd - fStart: .4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014f9ef6-1c7c-4ebc-8ff4-986e226a76f2",
   "metadata": {},
   "source": [
    "## Desayuno de David"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da34431f-17c6-4222-95bd-ed6c3702f395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egbuc\\cs634\\Egbuchulam_Chike_midtermproject\\tables\\desayunodedavid001.csv\n",
      "Frequent Sets: [{'Muffin', 'Coffee'}]\n",
      "\n",
      "\n",
      "Rule 1: Muffin ===> Coffee \t Confidence :1.0\n",
      "\n",
      "\n",
      "Rule 2: Coffee ===> Muffin \t Confidence :1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dbfile = os.path.join(tables_dir, \"desayunodedavid001.csv\")\n",
    "transactions = pd.read_csv(dbfile, usecols=[\"ItemsPurchased\"])\n",
    "transactions_set = transactions[\"ItemsPurchased\"].apply(lambda x: set(item.strip() for item in x.split(\",\"))).tolist()\n",
    "unique_items = set().union(*transactions_set)\n",
    "print(dbfile)\n",
    "\n",
    "bStart = time.perf_counter()\n",
    "[fSets,rules] = assocRules(unique_items,transactions_set,supportValue,confidenceValue)\n",
    "bEnd = time.perf_counter()\n",
    "\n",
    "\n",
    "print(f\"Frequent Sets: {fSets}\")\n",
    "print('\\n')\n",
    "\n",
    "if(rules != [] and supportValue!=0):\n",
    "    i = 1\n",
    "    for (a, b, c) in rules:\n",
    "        print(f\"Rule {i}: {a} ===> {b} \\t Confidence :{c}\")\n",
    "        print(\"\\n\")\n",
    "        i += 1\n",
    "else:\n",
    "    if supportValue == 0:\n",
    "        print(\n",
    "            \"At 0% support I have to look at possible menu pairing as a rule even if it happens only once. \"\n",
    "            \"So in other words, you're trying to waste my time so here is the whole list of transactions.\"\n",
    "        )\n",
    "        # print(transactions)\n",
    "\n",
    "    if supportValue != 0 and len(rules) == 0:\n",
    "        print(\"There are no rules that satisfy these minimum values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a08d3fc-eb0e-4c53-8ef1-2610096e6017",
   "metadata": {},
   "source": [
    "#### Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5123277-f2f5-40a9-9fcc-ef9f7bdc3ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apriori check:{frequent_items}\n",
      "Our Association Algorithm: 0.0036 seconds\n",
      "Apriori:0.0167 seconds\n",
      "FP-Growth: 0.0129 seconds\n"
     ]
    }
   ],
   "source": [
    "tList = transactions[\"ItemsPurchased\"].apply(lambda x: [item.strip() for item in x.split(\",\")]).tolist()\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(tList).transform(tList)\n",
    "df_encoded = pd.DataFrame(te_array, columns=te.columns_)\n",
    "\n",
    "aStart = time.perf_counter()\n",
    "frequent_items = apriori(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "aEnd = time.perf_counter()\n",
    "print(\"Apriori check:{frequent_items}\")\n",
    "fStart= time.perf_counter()\n",
    "frequent_items = fpgrowth(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "fEnd = time.perf_counter() \n",
    "\n",
    "print(f\"Our Association Algorithm: {bEnd - bStart:.4f} seconds\")\n",
    "print(f\"Apriori:{aEnd - aStart:.4f} seconds\")\n",
    "print(f\"FP-Growth:{fEnd - fStart: .4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c679e8b0-ade2-4705-9426-3e079eea22ef",
   "metadata": {},
   "source": [
    "## Eddie's Eats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ed02c77-04c8-4e4b-ad1b-861c4edad7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egbuc\\cs634\\Egbuchulam_Chike_midtermproject\\tables\\eddieseats001.csv\n",
      "Frequent Sets: [{'Coffee', 'Pastry'}]\n",
      "\n",
      "\n",
      "Rule 1: Pastry ===> Coffee \t Confidence :1.0\n",
      "\n",
      "\n",
      "Rule 2: Coffee ===> Pastry \t Confidence :1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dbfile = os.path.join(tables_dir, \"eddieseats001.csv\")\n",
    "transactions = pd.read_csv(dbfile, usecols=[\"ItemsPurchased\"])\n",
    "transactions_set = transactions[\"ItemsPurchased\"].apply(lambda x: set(item.strip() for item in x.split(\",\"))).tolist()\n",
    "unique_items = set().union(*transactions_set)\n",
    "print(dbfile)\n",
    "\n",
    "bStart = time.perf_counter()\n",
    "[fSets,rules] = assocRules(unique_items,transactions_set,supportValue,confidenceValue)\n",
    "bEnd = time.perf_counter()\n",
    "\n",
    "\n",
    "print(f\"Frequent Sets: {fSets}\")\n",
    "print('\\n')\n",
    "\n",
    "if(rules != [] and supportValue!=0):\n",
    "    i = 1\n",
    "    for (a, b, c) in rules:\n",
    "        print(f\"Rule {i}: {a} ===> {b} \\t Confidence :{c}\")\n",
    "        print(\"\\n\")\n",
    "        i += 1\n",
    "else:\n",
    "    if supportValue == 0:\n",
    "        print(\n",
    "            \"At 0% support I have to look at possible menu pairing as a rule even if it happens only once. \"\n",
    "            \"So in other words, you're trying to waste my time so here is the whole list of transactions.\"\n",
    "        )\n",
    "        # print(transactions)\n",
    "\n",
    "    if supportValue != 0 and len(rules) == 0:\n",
    "        print(\"There are no rules that satisfy these minimum values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1391dc88-69ea-4a9b-a482-55b068245514",
   "metadata": {},
   "source": [
    "#### Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c503fc95-2068-4e9c-a660-6e340bfe8d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apriori check:\n",
      "    support          itemsets\n",
      "0    0.275           (Bread)\n",
      "1    0.500          (Coffee)\n",
      "2    0.175          (Pastry)\n",
      "3    0.250             (Tea)\n",
      "4    0.100  (Pastry, Coffee)\n",
      "Our Association Algorithm: 0.0039 seconds\n",
      "Apriori:0.0158 seconds\n",
      "FP-Growth: 0.0084 seconds\n"
     ]
    }
   ],
   "source": [
    "tList = transactions[\"ItemsPurchased\"].apply(lambda x: [item.strip() for item in x.split(\",\")]).tolist()\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(tList).transform(tList)\n",
    "df_encoded = pd.DataFrame(te_array, columns=te.columns_)\n",
    "\n",
    "aStart = time.perf_counter()\n",
    "frequent_items = apriori(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "aEnd = time.perf_counter()\n",
    "print(f\"Apriori check:\\n {frequent_items}\")\n",
    "fStart= time.perf_counter()\n",
    "frequent_items = fpgrowth(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "fEnd = time.perf_counter() \n",
    "\n",
    "print(f\"Our Association Algorithm: {bEnd - bStart:.4f} seconds\")\n",
    "print(f\"Apriori:{aEnd - aStart:.4f} seconds\")\n",
    "print(f\"FP-Growth:{fEnd - fStart: .4f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
