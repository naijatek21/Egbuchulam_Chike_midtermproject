{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7891231-3313-4d3b-82f9-3f906308b167",
   "metadata": {},
   "source": [
    "# CS 634 Midterm Project              By Chike Egbuchulam(coe5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481c600f-4cf5-4320-b546-8168d59dfce4",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496cc2ad-238d-4e24-be34-d90a1dcb2dce",
   "metadata": {},
   "source": [
    "First you want to import the libraries essential to run the the FP and Apriori Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23ca2a48-4096-430e-ba94-b18a03350e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlxtend.frequent_patterns import apriori,fpgrowth, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import time\n",
    "import itertools\n",
    "from bfassociationrules import assocRules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd032f4-d3c2-4ad0-8d65-b415b094b187",
   "metadata": {},
   "source": [
    "### Set  the initital variables as well as the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6831ec83-a020-4cfa-a447-50139ed71efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory: C:\\Users\\egbuc\\cs634\\Egbuchulam_Chike_midtermproject\n",
      "Tables directory: C:\\Users\\egbuc\\cs634\\Egbuchulam_Chike_midtermproject\\tables\n"
     ]
    }
   ],
   "source": [
    "dbfile = \"\"\n",
    "stores = [\"Alice's Bakery\", \"Bob's Breakfast\", \"Charlie's Cafe\", \"Desayuno de David\", \"Eddie's Eatery\"]\n",
    "supportValue, confidenceValue = 0, 0\n",
    "\n",
    "base_dir = os.getcwd()\n",
    "tables_dir = os.path.join(base_dir, \"tables\")\n",
    "\n",
    "print(\"Base directory:\", base_dir)\n",
    "print(\"Tables directory:\", tables_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c31febd-d9ea-4893-8aec-cb40234081b9",
   "metadata": {},
   "source": [
    "### Now let's get the Minimum Support and Minimimum Confidence values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a856231-0c8e-484f-9487-fc2d82375916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the minimum support % you want (0-100):  5\n",
      "Please enter the minimum confidence % you want (0-100):  10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support 5.0 %\n",
      "Confidence 10.0 %\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    sV = input(\"Please enter the minimum support % you want (0-100): \")\n",
    "    try:\n",
    "        supportValue = float(sV) / 100\n",
    "    except ValueError:\n",
    "        print(\"Please input a numeric value\")\n",
    "        continue\n",
    "    if 0.0 <= supportValue <= 1.00:\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid selection\")\n",
    "\n",
    "while True:\n",
    "    cV = input(\"Please enter the minimum confidence % you want (0-100): \")\n",
    "    try:\n",
    "        confidenceValue = float(cV) / 100\n",
    "    except ValueError:\n",
    "        print(\"Please input a numeric value\")\n",
    "        continue\n",
    "    if 0.0 <= confidenceValue <= 1.0:\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid selection\")\n",
    "print(\"Support {} %\".format(supportValue * 100))\n",
    "print(\"Confidence {} %\".format(confidenceValue * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89498e52-3468-4331-840f-2f26df2d4101",
   "metadata": {},
   "source": [
    "### Now we'll run theses values for each database with our algorithm while also running the aprioiri and FP growth algorithms for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942f7674-80a4-459f-b265-ef1a23a752b7",
   "metadata": {},
   "source": [
    "## Alice's Bakery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f1830a-edaa-46a9-89e1-d91f8a7af9d1",
   "metadata": {},
   "source": [
    " Here is the transaction table for Alice's bakery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184dfd0d-4001-4ef0-931e-3b7d4c745345",
   "metadata": {},
   "source": [
    "### Here is the transaction table for Alice's bakery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a186fd3-bfcf-4d4d-9676-e8332df46ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egbuc\\cs634\\Egbuchulam_Chike_midtermproject\\tables\\alicebakery001.csv\n"
     ]
    }
   ],
   "source": [
    "dbfile = os.path.join(tables_dir, \"alicebakery001.csv\")\n",
    "transactions = pd.read_csv(dbfile, usecols=[\"ItemsPurchased\"])\n",
    "transactions_set = transactions[\"ItemsPurchased\"].apply(lambda x: set(item.strip() for item in x.split(\",\"))).tolist()\n",
    "unique_items = set().union(*transactions_set)\n",
    "print(dbfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127417b7-39d5-4a81-bd61-8b85d52f755f",
   "metadata": {},
   "source": [
    "### Now lets run the algorithm with the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47ffe72d-0ff8-4ee5-b5f9-251f5e504fd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'itertools' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m bStart = time.perf_counter()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m [fSets,rules] = \u001b[43massocRules\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtransactions_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43msupportValue\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfidenceValue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m bEnd = time.perf_counter()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\cs634\\Egbuchulam_Chike_midtermproject\\bfassociationrules.py:9\u001b[39m, in \u001b[36massocRules\u001b[39m\u001b[34m(items, dataTable, support_Val, confidence_Val)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m supported:\n\u001b[32m      8\u001b[39m     kSets = []\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     itemSets = \u001b[43mitertools\u001b[49m.combinations(items,k)\n\u001b[32m     10\u001b[39m     itemSets = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mset\u001b[39m, itemSets))\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# print(itemSets)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'itertools' is not defined"
     ]
    }
   ],
   "source": [
    "bStart = time.perf_counter()\n",
    "[fSets,rules] = assocRules(unique_items,transactions_set,supportValue,confidenceValue)\n",
    "bEnd = time.perf_counter()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc702bb4-9050-4f0e-91c1-dae0e157212f",
   "metadata": {},
   "source": [
    "### Here are the frequent sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4445a72f-d919-4ab2-a8c1-d17673dd4d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fSets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedb62aa-f794-45d1-9808-1531806028d4",
   "metadata": {},
   "source": [
    "### Here are the rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a14bca-41bf-4d0a-b73a-504627114c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(rules != [] and supportValue!=0):\n",
    "    i = 1\n",
    "    for (a, b, c) in rules:\n",
    "        print(f\"Rule {i}: {a} ===> {b} \\t Confidence :{c}\")\n",
    "        print(\"\\n\")\n",
    "        i += 1\n",
    "else:\n",
    "    if supportValue == 0:\n",
    "            print(\n",
    "                \"At 0% support I have to look at possible menu pairing as a rule even if it happens only once. \"\n",
    "                \"So in other words, you're trying to waste my time so here is the whole list of transactions.\"\n",
    "            )\n",
    "            # print(transactions)\n",
    "    \n",
    "    if supportValue != 0 and len(rules) == 0:\n",
    "        print(\"There are no rules that satisfy these minimum values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64962577-332f-4762-8f6a-d890d46f8f28",
   "metadata": {},
   "source": [
    "### Here's how it compares to other algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4b5dc1-0d86-4e72-9bb7-58de498f05bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tList = transactions[\"ItemsPurchased\"].apply(lambda x: [item.strip() for item in x.split(\",\")]).tolist()\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(tList).transform(tList)\n",
    "df_encoded = pd.DataFrame(te_array, columns=te.columns_)\n",
    "\n",
    "aStart = time.perf_counter()\n",
    "frequent_items = apriori(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "aEnd = time.perf_counter()\n",
    "print(f\"Apriori check:\\n {frequent_items}\")\n",
    "fStart= time.perf_counter()\n",
    "frequent_items = fpgrowth(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "fEnd = time.perf_counter() \n",
    "\n",
    "print(f\"Our Association Algorithm: {bEnd - bStart:.4f} seconds\")\n",
    "print(f\"Apriori:{aEnd - aStart:.4f} seconds\")\n",
    "print(f\"FP-Growth:{fEnd - fStart: .4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a798a6e-29ce-4c62-8664-4882c82c4fd9",
   "metadata": {},
   "source": [
    "### Now for the rest of the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cab03d-fd1f-4e26-96ad-e369e94805f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98603478-5f10-4562-8c73-054cddd385e2",
   "metadata": {},
   "source": [
    "## Bob's Breakfast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad78ac4f-810a-46d7-822c-3a65f915534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = os.path.join(tables_dir, \"bobsbreakfast001.csv\")\n",
    "transactions = pd.read_csv(dbfile, usecols=[\"ItemsPurchased\"])\n",
    "transactions_set = transactions[\"ItemsPurchased\"].apply(lambda x: set(item.strip() for item in x.split(\",\"))).tolist()\n",
    "unique_items = set().union(*transactions_set)\n",
    "print(dbfile)\n",
    "\n",
    "bStart = time.perf_counter()\n",
    "[fSets,rules] = assocRules(unique_items,transactions_set,supportValue,confidenceValue)\n",
    "bEnd = time.perf_counter()\n",
    "\n",
    "\n",
    "print(f\"Frequent Sets: {fSets}\")\n",
    "print('\\n')\n",
    "\n",
    "if(rules != [] and supportValue!=0):\n",
    "    i = 1\n",
    "    for (a, b, c) in rules:\n",
    "        print(f\"Rule {i}: {a} ===> {b} \\t Confidence :{c}\")\n",
    "        print(\"\\n\")\n",
    "        i += 1\n",
    "else:\n",
    "    if supportValue == 0:\n",
    "        print(\n",
    "            \"At 0% support I have to look at possible menu pairing as a rule even if it happens only once. \"\n",
    "            \"So in other words, you're trying to waste my time so here is the whole list of transactions.\"\n",
    "        )\n",
    "        # print(transactions)\n",
    "    \n",
    "    if supportValue != 0 and len(rules) == 0:\n",
    "        print(\"There are no rules that satisfy these minimum values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851afd9e-02e1-4b24-ab0a-e0e08d269c1c",
   "metadata": {},
   "source": [
    "#### Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c941e3-f3bb-4115-b87b-972f9ba56d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "tList = transactions[\"ItemsPurchased\"].apply(lambda x: [item.strip() for item in x.split(\",\")]).tolist()\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(tList).transform(tList)\n",
    "df_encoded = pd.DataFrame(te_array, columns=te.columns_)\n",
    "\n",
    "aStart = time.perf_counter()\n",
    "frequent_items = apriori(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "aEnd = time.perf_counter()\n",
    "print(f\"Apriori check:\\n {frequent_items}\")\n",
    "fStart= time.perf_counter()\n",
    "frequent_items = fpgrowth(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "fEnd = time.perf_counter() \n",
    "\n",
    "print(f\"Our Association Algorithm: {bEnd - bStart:.4f} seconds\")\n",
    "print(f\"Apriori:{aEnd - aStart:.4f} seconds\")\n",
    "print(f\"FP-Growth:{fEnd - fStart: .4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2371d7ac-5670-47dd-977f-7ecb9e29de24",
   "metadata": {},
   "source": [
    "## Charlie's Cafe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a08572-e139-40eb-8027-4bf7ec30b2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = os.path.join(tables_dir, \"charliescafe001.csv\")\n",
    "transactions = pd.read_csv(dbfile, usecols=[\"ItemsPurchased\"])\n",
    "transactions_set = transactions[\"ItemsPurchased\"].apply(lambda x: set(item.strip() for item in x.split(\",\"))).tolist()\n",
    "unique_items = set().union(*transactions_set)\n",
    "print(dbfile)\n",
    "\n",
    "bStart = time.perf_counter()\n",
    "[fSets,rules] = assocRules(unique_items,transactions_set,supportValue,confidenceValue)\n",
    "bEnd = time.perf_counter()\n",
    "\n",
    "\n",
    "print(f\"Frequent Sets: {fSets}\")\n",
    "print('\\n')\n",
    "\n",
    "if(rules != [] and supportValue!=0):\n",
    "    i = 1\n",
    "    for (a, b, c) in rules:\n",
    "        print(f\"Rule {i}: {a} ===> {b} \\t Confidence :{c}\")\n",
    "        print(\"\\n\")\n",
    "        i += 1\n",
    "else:\n",
    "    if supportValue == 0:\n",
    "        print(\n",
    "            \"At 0% support I have to look at possible menu pairing as a rule even if it happens only once. \"\n",
    "            \"So in other words, you're trying to waste my time so here is the whole list of transactions.\"\n",
    "        )\n",
    "        # print(transactions)\n",
    "\n",
    "    if supportValue != 0 and len(rules) == 0:\n",
    "        print(\"There are no rules that satisfy these minimum values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71ea3b0-88fb-4e74-a7de-708429c05c15",
   "metadata": {},
   "source": [
    "#### Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae3f943-1b5b-4c1a-a926-aef89815e7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tList = transactions[\"ItemsPurchased\"].apply(lambda x: [item.strip() for item in x.split(\",\")]).tolist()\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(tList).transform(tList)\n",
    "df_encoded = pd.DataFrame(te_array, columns=te.columns_)\n",
    "\n",
    "aStart = time.perf_counter()\n",
    "frequent_items = apriori(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "aEnd = time.perf_counter()\n",
    "print(f\"Apriori check:\\n {frequent_items}\")\n",
    "fStart= time.perf_counter()\n",
    "frequent_items = fpgrowth(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "fEnd = time.perf_counter() \n",
    "\n",
    "print(f\"Our Association Algorithm: {bEnd - bStart:.4f} seconds\")\n",
    "print(f\"Apriori:{aEnd - aStart:.4f} seconds\")\n",
    "print(f\"FP-Growth:{fEnd - fStart: .4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014f9ef6-1c7c-4ebc-8ff4-986e226a76f2",
   "metadata": {},
   "source": [
    "## Desayuno de David"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da34431f-17c6-4222-95bd-ed6c3702f395",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = os.path.join(tables_dir, \"desayunodedavid001.csv\")\n",
    "transactions = pd.read_csv(dbfile, usecols=[\"ItemsPurchased\"])\n",
    "transactions_set = transactions[\"ItemsPurchased\"].apply(lambda x: set(item.strip() for item in x.split(\",\"))).tolist()\n",
    "unique_items = set().union(*transactions_set)\n",
    "print(dbfile)\n",
    "\n",
    "bStart = time.perf_counter()\n",
    "[fSets,rules] = assocRules(unique_items,transactions_set,supportValue,confidenceValue)\n",
    "bEnd = time.perf_counter()\n",
    "\n",
    "\n",
    "print(f\"Frequent Sets: {fSets}\")\n",
    "print('\\n')\n",
    "\n",
    "if(rules != [] and supportValue!=0):\n",
    "    i = 1\n",
    "    for (a, b, c) in rules:\n",
    "        print(f\"Rule {i}: {a} ===> {b} \\t Confidence :{c}\")\n",
    "        print(\"\\n\")\n",
    "        i += 1\n",
    "else:\n",
    "    if supportValue == 0:\n",
    "        print(\n",
    "            \"At 0% support I have to look at possible menu pairing as a rule even if it happens only once. \"\n",
    "            \"So in other words, you're trying to waste my time so here is the whole list of transactions.\"\n",
    "        )\n",
    "        # print(transactions)\n",
    "\n",
    "    if supportValue != 0 and len(rules) == 0:\n",
    "        print(\"There are no rules that satisfy these minimum values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a08d3fc-eb0e-4c53-8ef1-2610096e6017",
   "metadata": {},
   "source": [
    "#### Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5123277-f2f5-40a9-9fcc-ef9f7bdc3ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tList = transactions[\"ItemsPurchased\"].apply(lambda x: [item.strip() for item in x.split(\",\")]).tolist()\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(tList).transform(tList)\n",
    "df_encoded = pd.DataFrame(te_array, columns=te.columns_)\n",
    "\n",
    "aStart = time.perf_counter()\n",
    "frequent_items = apriori(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "aEnd = time.perf_counter()\n",
    "print(\"Apriori check:{frequent_items}\")\n",
    "fStart= time.perf_counter()\n",
    "frequent_items = fpgrowth(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "fEnd = time.perf_counter() \n",
    "\n",
    "print(f\"Our Association Algorithm: {bEnd - bStart:.4f} seconds\")\n",
    "print(f\"Apriori:{aEnd - aStart:.4f} seconds\")\n",
    "print(f\"FP-Growth:{fEnd - fStart: .4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c679e8b0-ade2-4705-9426-3e079eea22ef",
   "metadata": {},
   "source": [
    "## Eddie's Eats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed02c77-04c8-4e4b-ad1b-861c4edad7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = os.path.join(tables_dir, \"eddieseats001.csv\")\n",
    "transactions = pd.read_csv(dbfile, usecols=[\"ItemsPurchased\"])\n",
    "transactions_set = transactions[\"ItemsPurchased\"].apply(lambda x: set(item.strip() for item in x.split(\",\"))).tolist()\n",
    "unique_items = set().union(*transactions_set)\n",
    "print(dbfile)\n",
    "\n",
    "bStart = time.perf_counter()\n",
    "[fSets,rules] = assocRules(unique_items,transactions_set,supportValue,confidenceValue)\n",
    "bEnd = time.perf_counter()\n",
    "\n",
    "\n",
    "print(f\"Frequent Sets: {fSets}\")\n",
    "print('\\n')\n",
    "\n",
    "if(rules != [] and supportValue!=0):\n",
    "    i = 1\n",
    "    for (a, b, c) in rules:\n",
    "        print(f\"Rule {i}: {a} ===> {b} \\t Confidence :{c}\")\n",
    "        print(\"\\n\")\n",
    "        i += 1\n",
    "else:\n",
    "    if supportValue == 0:\n",
    "        print(\n",
    "            \"At 0% support I have to look at possible menu pairing as a rule even if it happens only once. \"\n",
    "            \"So in other words, you're trying to waste my time so here is the whole list of transactions.\"\n",
    "        )\n",
    "        # print(transactions)\n",
    "\n",
    "    if supportValue != 0 and len(rules) == 0:\n",
    "        print(\"There are no rules that satisfy these minimum values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1391dc88-69ea-4a9b-a482-55b068245514",
   "metadata": {},
   "source": [
    "#### Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c503fc95-2068-4e9c-a660-6e340bfe8d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tList = transactions[\"ItemsPurchased\"].apply(lambda x: [item.strip() for item in x.split(\",\")]).tolist()\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(tList).transform(tList)\n",
    "df_encoded = pd.DataFrame(te_array, columns=te.columns_)\n",
    "\n",
    "aStart = time.perf_counter()\n",
    "frequent_items = apriori(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "aEnd = time.perf_counter()\n",
    "print(f\"Apriori check:\\n {frequent_items}\")\n",
    "fStart= time.perf_counter()\n",
    "frequent_items = fpgrowth(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "fEnd = time.perf_counter() \n",
    "\n",
    "print(f\"Our Association Algorithm: {bEnd - bStart:.4f} seconds\")\n",
    "print(f\"Apriori:{aEnd - aStart:.4f} seconds\")\n",
    "print(f\"FP-Growth:{fEnd - fStart: .4f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
