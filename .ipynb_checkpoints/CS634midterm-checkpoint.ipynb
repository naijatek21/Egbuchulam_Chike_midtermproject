{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7891231-3313-4d3b-82f9-3f906308b167",
   "metadata": {},
   "source": [
    "# CS 634 Midterm Project              By Chike Egbuchulam(coe5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481c600f-4cf5-4320-b546-8168d59dfce4",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496cc2ad-238d-4e24-be34-d90a1dcb2dce",
   "metadata": {},
   "source": [
    "First you want to import the libraries essential to run the the FP and Apriori Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23ca2a48-4096-430e-ba94-b18a03350e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlxtend.frequent_patterns import apriori,fpgrowth, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import time\n",
    "import itertools\n",
    "from bfassociationrules import assocRules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd032f4-d3c2-4ad0-8d65-b415b094b187",
   "metadata": {},
   "source": [
    "### Set  the initital variables as well as the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6831ec83-a020-4cfa-a447-50139ed71efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory: C:\\Users\\egbuc\\cs634\\Egbuchulam_Chike_midtermproject\n",
      "Tables directory: C:\\Users\\egbuc\\cs634\\Egbuchulam_Chike_midtermproject\\tables\n"
     ]
    }
   ],
   "source": [
    "dbfile = \"\"\n",
    "stores = [\"Alice's Bakery\", \"Bob's Breakfast\", \"Charlie's Cafe\", \"Desayuno de David\", \"Eddie's Eatery\"]\n",
    "supportValue, confidenceValue = 0, 0\n",
    "\n",
    "base_dir = os.getcwd()\n",
    "tables_dir = os.path.join(base_dir, \"tables\")\n",
    "\n",
    "print(\"Base directory:\", base_dir)\n",
    "print(\"Tables directory:\", tables_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c31febd-d9ea-4893-8aec-cb40234081b9",
   "metadata": {},
   "source": [
    "### Now let's get the Minimum Support and Minimimum Confidence values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a856231-0c8e-484f-9487-fc2d82375916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the minimum support % you want (0-100):  5\n",
      "Please enter the minimum confidence % you want (0-100):  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support 5.0 %\n",
      "Confidence 5.0 %\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    sV = input(\"Please enter the minimum support % you want (0-100): \")\n",
    "    try:\n",
    "        supportValue = float(sV) / 100\n",
    "    except ValueError:\n",
    "        print(\"Please input a numeric value\")\n",
    "        continue\n",
    "    if 0.0 <= supportValue <= 1.00:\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid selection\")\n",
    "\n",
    "while True:\n",
    "    cV = input(\"Please enter the minimum confidence % you want (0-100): \")\n",
    "    try:\n",
    "        confidenceValue = float(cV) / 100\n",
    "    except ValueError:\n",
    "        print(\"Please input a numeric value\")\n",
    "        continue\n",
    "    if 0.0 <= confidenceValue <= 1.0:\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid selection\")\n",
    "print(\"Support {} %\".format(supportValue * 100))\n",
    "print(\"Confidence {} %\".format(confidenceValue * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89498e52-3468-4331-840f-2f26df2d4101",
   "metadata": {},
   "source": [
    "### Now we'll run theses values for each dasta base while also running the aprioiri and FP growth algorithms for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304aff31-85ef-427c-9cca-95ef637392a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assocRules(items,dataTable,support_Val, confidence_Val):\n",
    "    rules = []\n",
    "    supported = True\n",
    "    k=1\n",
    "    # print(dataTable)\n",
    "    current_set = []\n",
    "    while supported:\n",
    "        kSets = []\n",
    "        itemSets = itertools.combinations(items,k)\n",
    "        itemSets = list(map(set, itemSets))\n",
    "        # print(itemSets)\n",
    "        for s in itemSets:\n",
    "                count =0\n",
    "                for row in dataTable:\n",
    "                    if s.issubset(row):\n",
    "                        count+=1\n",
    "                if count/len(dataTable) >= support_Val:\n",
    "                    kSets.append(s)\n",
    "        if len(kSets) == 0:\n",
    "            supported = False\n",
    "        current_set+=kSets\n",
    "        k+=1\n",
    "\n",
    "    # print(\"Frequent Itemsets:\")\n",
    "    rule_preview= {i:[] for i in items}\n",
    "    frequent_itemsets = [s for s in current_set if len(s)>=2]\n",
    "    # print(frequent_itemsets)\n",
    "    for i in items:\n",
    "        for s in frequent_itemsets:\n",
    "            if i in s:\n",
    "                rule_preview[i].append(s - {i})\n",
    "\n",
    "    rule_tracker = {s : 0 for s in list(itertools.permutations(items,2))}\n",
    "\n",
    "    for (a,b) in rule_tracker.keys():\n",
    "        for s in rule_preview[a]:\n",
    "            if b in s:\n",
    "                rule_tracker[(a,b)] +=1\n",
    "\n",
    "    for ((a,b), count) in rule_tracker.items():\n",
    "        if rule_preview[a]!=[]:\n",
    "            confidence = count / len(rule_preview[a])\n",
    "            if confidence >= confidence_Val:\n",
    "                rules.append((a,b,confidence))\n",
    "    # print(rules)\n",
    "    return [frequent_itemsets,rules]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942f7674-80a4-459f-b265-ef1a23a752b7",
   "metadata": {},
   "source": [
    "## Alice's Bakery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f1830a-edaa-46a9-89e1-d91f8a7af9d1",
   "metadata": {},
   "source": [
    " Here is the transaction table for Alice's bakery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184dfd0d-4001-4ef0-931e-3b7d4c745345",
   "metadata": {},
   "source": [
    "### Here is the transaction table for Alice's bakery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a186fd3-bfcf-4d4d-9676-e8332df46ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egbuc\\cs634\\Egbuchulam_Chike_midtermproject\\tables\\alicebakery001.csv\n"
     ]
    }
   ],
   "source": [
    "dbfile = os.path.join(tables_dir, \"alicebakery001.csv\")\n",
    "transactions = pd.read_csv(dbfile, usecols=[\"ItemsPurchased\"])\n",
    "transactions_set = transactions[\"ItemsPurchased\"].apply(lambda x: set(item.strip() for item in x.split(\",\"))).tolist()\n",
    "unique_items = set().union(*transactions_set)\n",
    "print(dbfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127417b7-39d5-4a81-bd61-8b85d52f755f",
   "metadata": {},
   "source": [
    "### Now lets run the algorithm with the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47ffe72d-0ff8-4ee5-b5f9-251f5e504fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bStart = time.perf_counter()\n",
    "[fSets,rules] = assocRules(unique_items,transactions_set,supportValue,confidenceValue)\n",
    "bEnd = time.perf_counter()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc702bb4-9050-4f0e-91c1-dae0e157212f",
   "metadata": {},
   "source": [
    "### Here are the frequent sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4445a72f-d919-4ab2-a8c1-d17673dd4d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Pastry', 'Tea'}, {'Bread', 'Pastry'}, {'Coffee', 'Pastry'}, {'Pastry', 'Medialuna'}, {'Bread', 'Tea'}, {'Coffee', 'Tea'}, {'Muffin', 'Scandinavian'}, {'Muffin', 'Coffee'}, {'Coffee', 'Bread'}, {'Bread', 'Medialuna'}, {'Coffee', 'Medialuna'}, {'Coffee', 'Pastry', 'Tea'}, {'Coffee', 'Bread', 'Medialuna'}]\n"
     ]
    }
   ],
   "source": [
    "print(fSets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedb62aa-f794-45d1-9808-1531806028d4",
   "metadata": {},
   "source": [
    "### Here are the rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8a14bca-41bf-4d0a-b73a-504627114c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule 1: Pastry ===> Tea \t Confidence :0.4\n",
      "\n",
      "\n",
      "Rule 2: Pastry ===> Bread \t Confidence :0.2\n",
      "\n",
      "\n",
      "Rule 3: Pastry ===> Coffee \t Confidence :0.4\n",
      "\n",
      "\n",
      "Rule 4: Pastry ===> Medialuna \t Confidence :0.2\n",
      "\n",
      "\n",
      "Rule 5: Tea ===> Pastry \t Confidence :0.5\n",
      "\n",
      "\n",
      "Rule 6: Tea ===> Bread \t Confidence :0.25\n",
      "\n",
      "\n",
      "Rule 7: Tea ===> Coffee \t Confidence :0.5\n",
      "\n",
      "\n",
      "Rule 8: Scandinavian ===> Muffin \t Confidence :1.0\n",
      "\n",
      "\n",
      "Rule 9: Muffin ===> Scandinavian \t Confidence :0.5\n",
      "\n",
      "\n",
      "Rule 10: Muffin ===> Coffee \t Confidence :0.5\n",
      "\n",
      "\n",
      "Rule 11: Bread ===> Pastry \t Confidence :0.2\n",
      "\n",
      "\n",
      "Rule 12: Bread ===> Tea \t Confidence :0.2\n",
      "\n",
      "\n",
      "Rule 13: Bread ===> Coffee \t Confidence :0.4\n",
      "\n",
      "\n",
      "Rule 14: Bread ===> Medialuna \t Confidence :0.4\n",
      "\n",
      "\n",
      "Rule 15: Coffee ===> Pastry \t Confidence :0.2857142857142857\n",
      "\n",
      "\n",
      "Rule 16: Coffee ===> Tea \t Confidence :0.2857142857142857\n",
      "\n",
      "\n",
      "Rule 17: Coffee ===> Muffin \t Confidence :0.14285714285714285\n",
      "\n",
      "\n",
      "Rule 18: Coffee ===> Bread \t Confidence :0.2857142857142857\n",
      "\n",
      "\n",
      "Rule 19: Coffee ===> Medialuna \t Confidence :0.2857142857142857\n",
      "\n",
      "\n",
      "Rule 20: Medialuna ===> Pastry \t Confidence :0.25\n",
      "\n",
      "\n",
      "Rule 21: Medialuna ===> Bread \t Confidence :0.5\n",
      "\n",
      "\n",
      "Rule 22: Medialuna ===> Coffee \t Confidence :0.5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if(rules != [] and supportValue!=0):\n",
    "    i = 1\n",
    "    for (a, b, c) in rules:\n",
    "        print(f\"Rule {i}: {a} ===> {b} \\t Confidence :{c}\")\n",
    "        print(\"\\n\")\n",
    "        i += 1\n",
    "else:\n",
    "    if supportValue == 0:\n",
    "            print(\n",
    "                \"At 0% support I have to look at possible menu pairing as a rule even if it happens only once. \"\n",
    "                \"So in other words, you're trying to waste my time so here is the whole list of transactions.\"\n",
    "            )\n",
    "            # print(transactions)\n",
    "    \n",
    "    if supportValue != 0 and len(rules) == 0:\n",
    "        print(\"There are no rules that satisfy these minimum values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64962577-332f-4762-8f6a-d890d46f8f28",
   "metadata": {},
   "source": [
    "### Here's how it compares to other algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e4b5dc1-0d86-4e72-9bb7-58de498f05bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apriori check:\n",
      "     support                    itemsets\n",
      "0     0.450                     (Bread)\n",
      "1     0.275                    (Coffee)\n",
      "2     0.050                (Farm House)\n",
      "3     0.050             (Hot chocolate)\n",
      "4     0.100                       (Jam)\n",
      "5     0.200                 (Medialuna)\n",
      "6     0.200                    (Muffin)\n",
      "7     0.150                    (Pastry)\n",
      "8     0.250              (Scandinavian)\n",
      "9     0.100                       (Tea)\n",
      "10    0.150             (Coffee, Bread)\n",
      "11    0.125          (Bread, Medialuna)\n",
      "12    0.075             (Bread, Pastry)\n",
      "13    0.050                (Bread, Tea)\n",
      "14    0.075         (Coffee, Medialuna)\n",
      "15    0.050            (Muffin, Coffee)\n",
      "16    0.075            (Coffee, Pastry)\n",
      "17    0.050               (Coffee, Tea)\n",
      "18    0.075         (Pastry, Medialuna)\n",
      "19    0.075      (Muffin, Scandinavian)\n",
      "20    0.050               (Pastry, Tea)\n",
      "21    0.050  (Coffee, Bread, Medialuna)\n",
      "22    0.050       (Coffee, Pastry, Tea)\n",
      "Our Association Algorithm: 0.0114 seconds\n",
      "Apriori:0.0339 seconds\n",
      "FP-Growth: 0.0331 seconds\n"
     ]
    }
   ],
   "source": [
    "tList = transactions[\"ItemsPurchased\"].apply(lambda x: [item.strip() for item in x.split(\",\")]).tolist()\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(tList).transform(tList)\n",
    "df_encoded = pd.DataFrame(te_array, columns=te.columns_)\n",
    "\n",
    "aStart = time.perf_counter()\n",
    "frequent_items = apriori(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "aEnd = time.perf_counter()\n",
    "print(f\"Apriori check:\\n {frequent_items}\")\n",
    "fStart= time.perf_counter()\n",
    "frequent_items = fpgrowth(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "fEnd = time.perf_counter() \n",
    "\n",
    "print(f\"Our Association Algorithm: {bEnd - bStart:.4f} seconds\")\n",
    "print(f\"Apriori:{aEnd - aStart:.4f} seconds\")\n",
    "print(f\"FP-Growth:{fEnd - fStart: .4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a798a6e-29ce-4c62-8664-4882c82c4fd9",
   "metadata": {},
   "source": [
    "### Now for the rest of the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cab03d-fd1f-4e26-96ad-e369e94805f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98603478-5f10-4562-8c73-054cddd385e2",
   "metadata": {},
   "source": [
    "## Bob's Breakfast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad78ac4f-810a-46d7-822c-3a65f915534f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egbuc\\cs634\\Egbuchulam_Chike_midtermproject\\tables\\bobsbreakfast001.csv\n",
      "Frequent Sets: [{'Hearty & Seasonal', 'Coffee'}, {'Hearty & Seasonal', 'Mineral water'}, {'Coffee', 'Tea'}, {'Coffee', 'Bread'}, {'Coffee', 'Medialuna'}, {'Bread', 'Tea'}]\n",
      "\n",
      "\n",
      "Rule 1: Hearty & Seasonal ===> Coffee \t Confidence :0.5\n",
      "\n",
      "\n",
      "Rule 2: Hearty & Seasonal ===> Mineral water \t Confidence :0.5\n",
      "\n",
      "\n",
      "Rule 3: Coffee ===> Hearty & Seasonal \t Confidence :0.25\n",
      "\n",
      "\n",
      "Rule 4: Coffee ===> Tea \t Confidence :0.25\n",
      "\n",
      "\n",
      "Rule 5: Coffee ===> Bread \t Confidence :0.25\n",
      "\n",
      "\n",
      "Rule 6: Coffee ===> Medialuna \t Confidence :0.25\n",
      "\n",
      "\n",
      "Rule 7: Mineral water ===> Hearty & Seasonal \t Confidence :1.0\n",
      "\n",
      "\n",
      "Rule 8: Tea ===> Coffee \t Confidence :0.5\n",
      "\n",
      "\n",
      "Rule 9: Tea ===> Bread \t Confidence :0.5\n",
      "\n",
      "\n",
      "Rule 10: Bread ===> Coffee \t Confidence :0.5\n",
      "\n",
      "\n",
      "Rule 11: Bread ===> Tea \t Confidence :0.5\n",
      "\n",
      "\n",
      "Rule 12: Medialuna ===> Coffee \t Confidence :1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dbfile = os.path.join(tables_dir, \"bobsbreakfast001.csv\")\n",
    "transactions = pd.read_csv(dbfile, usecols=[\"ItemsPurchased\"])\n",
    "transactions_set = transactions[\"ItemsPurchased\"].apply(lambda x: set(item.strip() for item in x.split(\",\"))).tolist()\n",
    "unique_items = set().union(*transactions_set)\n",
    "print(dbfile)\n",
    "\n",
    "bStart = time.perf_counter()\n",
    "[fSets,rules] = assocRules(unique_items,transactions_set,supportValue,confidenceValue)\n",
    "bEnd = time.perf_counter()\n",
    "\n",
    "\n",
    "print(f\"Frequent Sets: {fSets}\")\n",
    "print('\\n')\n",
    "\n",
    "if(rules != [] and supportValue!=0):\n",
    "    i = 1\n",
    "    for (a, b, c) in rules:\n",
    "        print(f\"Rule {i}: {a} ===> {b} \\t Confidence :{c}\")\n",
    "        print(\"\\n\")\n",
    "        i += 1\n",
    "else:\n",
    "    if supportValue == 0:\n",
    "        print(\n",
    "            \"At 0% support I have to look at possible menu pairing as a rule even if it happens only once. \"\n",
    "            \"So in other words, you're trying to waste my time so here is the whole list of transactions.\"\n",
    "        )\n",
    "        # print(transactions)\n",
    "    \n",
    "    if supportValue != 0 and len(rules) == 0:\n",
    "        print(\"There are no rules that satisfy these minimum values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851afd9e-02e1-4b24-ab0a-e0e08d269c1c",
   "metadata": {},
   "source": [
    "#### Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51c941e3-f3bb-4115-b87b-972f9ba56d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apriori check:\n",
      "     support                            itemsets\n",
      "0     0.275                             (Bread)\n",
      "1     0.050                              (Cake)\n",
      "2     0.475                            (Coffee)\n",
      "3     0.100                             (Fudge)\n",
      "4     0.100                 (Hearty & Seasonal)\n",
      "5     0.050                     (Hot chocolate)\n",
      "6     0.050                               (Jam)\n",
      "7     0.050                             (Juice)\n",
      "8     0.075                         (Medialuna)\n",
      "9     0.050                     (Mineral water)\n",
      "10    0.100                            (Muffin)\n",
      "11    0.125                      (Scandinavian)\n",
      "12    0.200                               (Tea)\n",
      "13    0.075                     (Coffee, Bread)\n",
      "14    0.050                        (Bread, Tea)\n",
      "15    0.050         (Hearty & Seasonal, Coffee)\n",
      "16    0.075                 (Coffee, Medialuna)\n",
      "17    0.100                       (Coffee, Tea)\n",
      "18    0.050  (Hearty & Seasonal, Mineral water)\n",
      "Our Association Algorithm: 0.0061 seconds\n",
      "Apriori:0.0284 seconds\n",
      "FP-Growth: 0.0248 seconds\n"
     ]
    }
   ],
   "source": [
    "tList = transactions[\"ItemsPurchased\"].apply(lambda x: [item.strip() for item in x.split(\",\")]).tolist()\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(tList).transform(tList)\n",
    "df_encoded = pd.DataFrame(te_array, columns=te.columns_)\n",
    "\n",
    "aStart = time.perf_counter()\n",
    "frequent_items = apriori(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "aEnd = time.perf_counter()\n",
    "print(f\"Apriori check:\\n {frequent_items}\")\n",
    "fStart= time.perf_counter()\n",
    "frequent_items = fpgrowth(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "fEnd = time.perf_counter() \n",
    "\n",
    "print(f\"Our Association Algorithm: {bEnd - bStart:.4f} seconds\")\n",
    "print(f\"Apriori:{aEnd - aStart:.4f} seconds\")\n",
    "print(f\"FP-Growth:{fEnd - fStart: .4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2371d7ac-5670-47dd-977f-7ecb9e29de24",
   "metadata": {},
   "source": [
    "## Charlie's Cafe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2a08572-e139-40eb-8027-4bf7ec30b2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egbuc\\cs634\\Egbuchulam_Chike_midtermproject\\tables\\charliescafe001.csv\n",
      "Frequent Sets: [{'Cake', 'Coffee'}, {'Juice', 'Pastry'}, {'Coffee', 'Juice'}, {'Pastry', 'Tea'}, {'Bread', 'Pastry'}, {'Coffee', 'Pastry'}, {'Coffee', 'Tea'}, {'Muffin', 'Coffee'}, {'Coffee', 'Bread'}, {'Coffee', 'Medialuna'}, {'Coffee', 'Juice', 'Pastry'}]\n",
      "\n",
      "\n",
      "Rule 1: Cake ===> Coffee \t Confidence :1.0\n",
      "\n",
      "\n",
      "Rule 2: Juice ===> Pastry \t Confidence :0.6666666666666666\n",
      "\n",
      "\n",
      "Rule 3: Juice ===> Coffee \t Confidence :0.6666666666666666\n",
      "\n",
      "\n",
      "Rule 4: Pastry ===> Juice \t Confidence :0.4\n",
      "\n",
      "\n",
      "Rule 5: Pastry ===> Tea \t Confidence :0.2\n",
      "\n",
      "\n",
      "Rule 6: Pastry ===> Bread \t Confidence :0.2\n",
      "\n",
      "\n",
      "Rule 7: Pastry ===> Coffee \t Confidence :0.4\n",
      "\n",
      "\n",
      "Rule 8: Tea ===> Pastry \t Confidence :0.5\n",
      "\n",
      "\n",
      "Rule 9: Tea ===> Coffee \t Confidence :0.5\n",
      "\n",
      "\n",
      "Rule 10: Muffin ===> Coffee \t Confidence :1.0\n",
      "\n",
      "\n",
      "Rule 11: Bread ===> Pastry \t Confidence :0.5\n",
      "\n",
      "\n",
      "Rule 12: Bread ===> Coffee \t Confidence :0.5\n",
      "\n",
      "\n",
      "Rule 13: Coffee ===> Cake \t Confidence :0.125\n",
      "\n",
      "\n",
      "Rule 14: Coffee ===> Juice \t Confidence :0.25\n",
      "\n",
      "\n",
      "Rule 15: Coffee ===> Pastry \t Confidence :0.25\n",
      "\n",
      "\n",
      "Rule 16: Coffee ===> Tea \t Confidence :0.125\n",
      "\n",
      "\n",
      "Rule 17: Coffee ===> Muffin \t Confidence :0.125\n",
      "\n",
      "\n",
      "Rule 18: Coffee ===> Bread \t Confidence :0.125\n",
      "\n",
      "\n",
      "Rule 19: Coffee ===> Medialuna \t Confidence :0.125\n",
      "\n",
      "\n",
      "Rule 20: Medialuna ===> Coffee \t Confidence :1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dbfile = os.path.join(tables_dir, \"charliescafe001.csv\")\n",
    "transactions = pd.read_csv(dbfile, usecols=[\"ItemsPurchased\"])\n",
    "transactions_set = transactions[\"ItemsPurchased\"].apply(lambda x: set(item.strip() for item in x.split(\",\"))).tolist()\n",
    "unique_items = set().union(*transactions_set)\n",
    "print(dbfile)\n",
    "\n",
    "bStart = time.perf_counter()\n",
    "[fSets,rules] = assocRules(unique_items,transactions_set,supportValue,confidenceValue)\n",
    "bEnd = time.perf_counter()\n",
    "\n",
    "\n",
    "print(f\"Frequent Sets: {fSets}\")\n",
    "print('\\n')\n",
    "\n",
    "if(rules != [] and supportValue!=0):\n",
    "    i = 1\n",
    "    for (a, b, c) in rules:\n",
    "        print(f\"Rule {i}: {a} ===> {b} \\t Confidence :{c}\")\n",
    "        print(\"\\n\")\n",
    "        i += 1\n",
    "else:\n",
    "    if supportValue == 0:\n",
    "        print(\n",
    "            \"At 0% support I have to look at possible menu pairing as a rule even if it happens only once. \"\n",
    "            \"So in other words, you're trying to waste my time so here is the whole list of transactions.\"\n",
    "        )\n",
    "        # print(transactions)\n",
    "\n",
    "    if supportValue != 0 and len(rules) == 0:\n",
    "        print(\"There are no rules that satisfy these minimum values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71ea3b0-88fb-4e74-a7de-708429c05c15",
   "metadata": {},
   "source": [
    "#### Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ae3f943-1b5b-4c1a-a926-aef89815e7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apriori check:\n",
      "     support                 itemsets\n",
      "0     0.300                  (Bread)\n",
      "1     0.075                   (Cake)\n",
      "2     0.525                 (Coffee)\n",
      "3     0.075                (Cookies)\n",
      "4     0.150             (Farm House)\n",
      "5     0.075                  (Juice)\n",
      "6     0.050              (Medialuna)\n",
      "7     0.100                 (Muffin)\n",
      "8     0.250                 (Pastry)\n",
      "9     0.125                    (Tea)\n",
      "10    0.100          (Coffee, Bread)\n",
      "11    0.050          (Bread, Pastry)\n",
      "12    0.075           (Cake, Coffee)\n",
      "13    0.050          (Coffee, Juice)\n",
      "14    0.050      (Coffee, Medialuna)\n",
      "15    0.050         (Muffin, Coffee)\n",
      "16    0.150         (Coffee, Pastry)\n",
      "17    0.050            (Coffee, Tea)\n",
      "18    0.050          (Juice, Pastry)\n",
      "19    0.050            (Pastry, Tea)\n",
      "20    0.050  (Coffee, Juice, Pastry)\n",
      "Our Association Algorithm: 0.0069 seconds\n",
      "Apriori:0.0263 seconds\n",
      "FP-Growth: 0.0347 seconds\n"
     ]
    }
   ],
   "source": [
    "tList = transactions[\"ItemsPurchased\"].apply(lambda x: [item.strip() for item in x.split(\",\")]).tolist()\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(tList).transform(tList)\n",
    "df_encoded = pd.DataFrame(te_array, columns=te.columns_)\n",
    "\n",
    "aStart = time.perf_counter()\n",
    "frequent_items = apriori(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "aEnd = time.perf_counter()\n",
    "print(f\"Apriori check:\\n {frequent_items}\")\n",
    "fStart= time.perf_counter()\n",
    "frequent_items = fpgrowth(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "fEnd = time.perf_counter() \n",
    "\n",
    "print(f\"Our Association Algorithm: {bEnd - bStart:.4f} seconds\")\n",
    "print(f\"Apriori:{aEnd - aStart:.4f} seconds\")\n",
    "print(f\"FP-Growth:{fEnd - fStart: .4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014f9ef6-1c7c-4ebc-8ff4-986e226a76f2",
   "metadata": {},
   "source": [
    "## Desayuno de David"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da34431f-17c6-4222-95bd-ed6c3702f395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egbuc\\cs634\\Egbuchulam_Chike_midtermproject\\tables\\desayunodedavid001.csv\n",
      "Frequent Sets: [{'Muffin', 'Tea'}, {'Cookies', 'Tea'}, {'Coffee', 'Tea'}, {'Coffee', 'Jam'}, {'Muffin', 'Coffee'}, {'Hearty & Seasonal', 'Coffee'}, {'Hearty & Seasonal', 'Soup'}, {'Coffee', 'Bread'}, {'Cookies', 'Coffee'}, {'Coffee', 'Soup'}]\n",
      "\n",
      "\n",
      "Rule 1: Tea ===> Muffin \t Confidence :0.3333333333333333\n",
      "\n",
      "\n",
      "Rule 2: Tea ===> Cookies \t Confidence :0.3333333333333333\n",
      "\n",
      "\n",
      "Rule 3: Tea ===> Coffee \t Confidence :0.3333333333333333\n",
      "\n",
      "\n",
      "Rule 4: Jam ===> Coffee \t Confidence :1.0\n",
      "\n",
      "\n",
      "Rule 5: Muffin ===> Tea \t Confidence :0.5\n",
      "\n",
      "\n",
      "Rule 6: Muffin ===> Coffee \t Confidence :0.5\n",
      "\n",
      "\n",
      "Rule 7: Hearty & Seasonal ===> Coffee \t Confidence :0.5\n",
      "\n",
      "\n",
      "Rule 8: Hearty & Seasonal ===> Soup \t Confidence :0.5\n",
      "\n",
      "\n",
      "Rule 9: Bread ===> Coffee \t Confidence :1.0\n",
      "\n",
      "\n",
      "Rule 10: Cookies ===> Tea \t Confidence :0.5\n",
      "\n",
      "\n",
      "Rule 11: Cookies ===> Coffee \t Confidence :0.5\n",
      "\n",
      "\n",
      "Rule 12: Coffee ===> Tea \t Confidence :0.14285714285714285\n",
      "\n",
      "\n",
      "Rule 13: Coffee ===> Jam \t Confidence :0.14285714285714285\n",
      "\n",
      "\n",
      "Rule 14: Coffee ===> Muffin \t Confidence :0.14285714285714285\n",
      "\n",
      "\n",
      "Rule 15: Coffee ===> Hearty & Seasonal \t Confidence :0.14285714285714285\n",
      "\n",
      "\n",
      "Rule 16: Coffee ===> Bread \t Confidence :0.14285714285714285\n",
      "\n",
      "\n",
      "Rule 17: Coffee ===> Cookies \t Confidence :0.14285714285714285\n",
      "\n",
      "\n",
      "Rule 18: Coffee ===> Soup \t Confidence :0.14285714285714285\n",
      "\n",
      "\n",
      "Rule 19: Soup ===> Hearty & Seasonal \t Confidence :0.5\n",
      "\n",
      "\n",
      "Rule 20: Soup ===> Coffee \t Confidence :0.5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dbfile = os.path.join(tables_dir, \"desayunodedavid001.csv\")\n",
    "transactions = pd.read_csv(dbfile, usecols=[\"ItemsPurchased\"])\n",
    "transactions_set = transactions[\"ItemsPurchased\"].apply(lambda x: set(item.strip() for item in x.split(\",\"))).tolist()\n",
    "unique_items = set().union(*transactions_set)\n",
    "print(dbfile)\n",
    "\n",
    "bStart = time.perf_counter()\n",
    "[fSets,rules] = assocRules(unique_items,transactions_set,supportValue,confidenceValue)\n",
    "bEnd = time.perf_counter()\n",
    "\n",
    "\n",
    "print(f\"Frequent Sets: {fSets}\")\n",
    "print('\\n')\n",
    "\n",
    "if(rules != [] and supportValue!=0):\n",
    "    i = 1\n",
    "    for (a, b, c) in rules:\n",
    "        print(f\"Rule {i}: {a} ===> {b} \\t Confidence :{c}\")\n",
    "        print(\"\\n\")\n",
    "        i += 1\n",
    "else:\n",
    "    if supportValue == 0:\n",
    "        print(\n",
    "            \"At 0% support I have to look at possible menu pairing as a rule even if it happens only once. \"\n",
    "            \"So in other words, you're trying to waste my time so here is the whole list of transactions.\"\n",
    "        )\n",
    "        # print(transactions)\n",
    "\n",
    "    if supportValue != 0 and len(rules) == 0:\n",
    "        print(\"There are no rules that satisfy these minimum values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a08d3fc-eb0e-4c53-8ef1-2610096e6017",
   "metadata": {},
   "source": [
    "#### Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5123277-f2f5-40a9-9fcc-ef9f7bdc3ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apriori check:{frequent_items}\n",
      "Our Association Algorithm: 0.0083 seconds\n",
      "Apriori:0.0285 seconds\n",
      "FP-Growth: 0.0251 seconds\n"
     ]
    }
   ],
   "source": [
    "tList = transactions[\"ItemsPurchased\"].apply(lambda x: [item.strip() for item in x.split(\",\")]).tolist()\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(tList).transform(tList)\n",
    "df_encoded = pd.DataFrame(te_array, columns=te.columns_)\n",
    "\n",
    "aStart = time.perf_counter()\n",
    "frequent_items = apriori(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "aEnd = time.perf_counter()\n",
    "print(\"Apriori check:{frequent_items}\")\n",
    "fStart= time.perf_counter()\n",
    "frequent_items = fpgrowth(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "fEnd = time.perf_counter() \n",
    "\n",
    "print(f\"Our Association Algorithm: {bEnd - bStart:.4f} seconds\")\n",
    "print(f\"Apriori:{aEnd - aStart:.4f} seconds\")\n",
    "print(f\"FP-Growth:{fEnd - fStart: .4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c679e8b0-ade2-4705-9426-3e079eea22ef",
   "metadata": {},
   "source": [
    "## Eddie's Eats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ed02c77-04c8-4e4b-ad1b-861c4edad7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egbuc\\cs634\\Egbuchulam_Chike_midtermproject\\tables\\eddieseats001.csv\n",
      "Frequent Sets: [{'Coffee', 'Pastry'}, {'Coffee', 'Tea'}, {'Tea', 'Soup'}, {'Muffin', 'Coffee'}, {'Coffee', 'Bread'}, {'Cookies', 'Coffee'}]\n",
      "\n",
      "\n",
      "Rule 1: Pastry ===> Coffee \t Confidence :1.0\n",
      "\n",
      "\n",
      "Rule 2: Tea ===> Coffee \t Confidence :0.5\n",
      "\n",
      "\n",
      "Rule 3: Tea ===> Soup \t Confidence :0.5\n",
      "\n",
      "\n",
      "Rule 4: Muffin ===> Coffee \t Confidence :1.0\n",
      "\n",
      "\n",
      "Rule 5: Bread ===> Coffee \t Confidence :1.0\n",
      "\n",
      "\n",
      "Rule 6: Cookies ===> Coffee \t Confidence :1.0\n",
      "\n",
      "\n",
      "Rule 7: Coffee ===> Pastry \t Confidence :0.2\n",
      "\n",
      "\n",
      "Rule 8: Coffee ===> Tea \t Confidence :0.2\n",
      "\n",
      "\n",
      "Rule 9: Coffee ===> Muffin \t Confidence :0.2\n",
      "\n",
      "\n",
      "Rule 10: Coffee ===> Bread \t Confidence :0.2\n",
      "\n",
      "\n",
      "Rule 11: Coffee ===> Cookies \t Confidence :0.2\n",
      "\n",
      "\n",
      "Rule 12: Soup ===> Tea \t Confidence :1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dbfile = os.path.join(tables_dir, \"eddieseats001.csv\")\n",
    "transactions = pd.read_csv(dbfile, usecols=[\"ItemsPurchased\"])\n",
    "transactions_set = transactions[\"ItemsPurchased\"].apply(lambda x: set(item.strip() for item in x.split(\",\"))).tolist()\n",
    "unique_items = set().union(*transactions_set)\n",
    "print(dbfile)\n",
    "\n",
    "bStart = time.perf_counter()\n",
    "[fSets,rules] = assocRules(unique_items,transactions_set,supportValue,confidenceValue)\n",
    "bEnd = time.perf_counter()\n",
    "\n",
    "\n",
    "print(f\"Frequent Sets: {fSets}\")\n",
    "print('\\n')\n",
    "\n",
    "if(rules != [] and supportValue!=0):\n",
    "    i = 1\n",
    "    for (a, b, c) in rules:\n",
    "        print(f\"Rule {i}: {a} ===> {b} \\t Confidence :{c}\")\n",
    "        print(\"\\n\")\n",
    "        i += 1\n",
    "else:\n",
    "    if supportValue == 0:\n",
    "        print(\n",
    "            \"At 0% support I have to look at possible menu pairing as a rule even if it happens only once. \"\n",
    "            \"So in other words, you're trying to waste my time so here is the whole list of transactions.\"\n",
    "        )\n",
    "        # print(transactions)\n",
    "\n",
    "    if supportValue != 0 and len(rules) == 0:\n",
    "        print(\"There are no rules that satisfy these minimum values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1391dc88-69ea-4a9b-a482-55b068245514",
   "metadata": {},
   "source": [
    "#### Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c503fc95-2068-4e9c-a660-6e340bfe8d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apriori check:\n",
      "     support           itemsets\n",
      "0     0.275            (Bread)\n",
      "1     0.500           (Coffee)\n",
      "2     0.075          (Cookies)\n",
      "3     0.050    (Mineral water)\n",
      "4     0.075           (Muffin)\n",
      "5     0.175           (Pastry)\n",
      "6     0.050             (Soup)\n",
      "7     0.250              (Tea)\n",
      "8     0.050    (Coffee, Bread)\n",
      "9     0.050  (Coffee, Cookies)\n",
      "10    0.050   (Muffin, Coffee)\n",
      "11    0.100   (Coffee, Pastry)\n",
      "12    0.050      (Coffee, Tea)\n",
      "13    0.050        (Tea, Soup)\n",
      "Our Association Algorithm: 0.0059 seconds\n",
      "Apriori:0.0319 seconds\n",
      "FP-Growth: 0.0341 seconds\n"
     ]
    }
   ],
   "source": [
    "tList = transactions[\"ItemsPurchased\"].apply(lambda x: [item.strip() for item in x.split(\",\")]).tolist()\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(tList).transform(tList)\n",
    "df_encoded = pd.DataFrame(te_array, columns=te.columns_)\n",
    "\n",
    "aStart = time.perf_counter()\n",
    "frequent_items = apriori(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "aEnd = time.perf_counter()\n",
    "print(f\"Apriori check:\\n {frequent_items}\")\n",
    "fStart= time.perf_counter()\n",
    "frequent_items = fpgrowth(df_encoded, min_support=supportValue, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=confidenceValue)\n",
    "fEnd = time.perf_counter() \n",
    "\n",
    "print(f\"Our Association Algorithm: {bEnd - bStart:.4f} seconds\")\n",
    "print(f\"Apriori:{aEnd - aStart:.4f} seconds\")\n",
    "print(f\"FP-Growth:{fEnd - fStart: .4f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
